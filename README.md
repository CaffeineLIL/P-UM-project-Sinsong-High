# 신송고 프로젝트 양질의 교육

메인 주제 : AI가 인종에 따라 해당 문화권의 전문분야를 어떻게 편향되어 평가하는가?
해당 문화권 = 미국

그럼 AI가 인종별 소득에 따라 편향된 시각을 가지게 되는가?

인종별로 임금의 격차가 있는데, 해당 자료를 가지고 AI가 특정 인종(백인,흑인, 아시아인 등..)에 대해 편향된 시각을 가지고 있지 않을까? (예시 : 그림 생성 AI를 사용했을 때, CEO는 백인 남성이다.)<br>
인종별 임금격차가 왜 해당 문제에 대한 문제상황 제시가 되는가?미국은 자본주의 사회니까, 소득에 따른 생활 수준이 다르니 여기서 자연스레 사회 갈등이 일어날 수 밖에 없고, 그렇게 사람들마다 편향된 시각이 생겨서 해당 데이터를 AI가 그대로 학습한 게 아닐까?

--------------------------------------------------------------------------
왜? 인종별 소득 격차가 편향을 만들어 내는가?<br>
-> 소득 격차가 존재하여 상대적 부유층이 양질의 교육을 받을 기회가 더 많아 교육 기회의 격차가 생기게 된다. 해당 차이는 그대로 AI가 학습할 수 있는 데이터의 양의 차이를 만들어 내므로, 해당 데이터는 경제적으로 어려운 사람들을 과소 대표하게 된다. 이는 자연스럽게 AI의 편향으로 이어지게 된다.<br>
<br>
그럼 앞으로 우리는 AI가 이런 편향을 가지지 않도록 어떤 노력을 기울여야 하는가?<br>
사회적 해결법, 기술적 해결법으로 나누어서 프로젝트 발표 구성하기<br>
<br>
● AI 기술이 계속 발달하고 있음에 따라 편향성 문제에 대한 지속적인 감시와 심도있는 연구등이 필수적이기 떄문에 AI윤리위원회같은 기관을 만들어 모델링 할 때 검토하고 모델링하기<br>
<br>
● 인종 때문에 생기는 고용이나 임금에서의 차이도 발생해서는 안 되지만, 인종에 관계없이 양질의 교육을 동등하게 받을 수 있도록 해야 한다.<br>
<br>
● 저소득층 및 소외된 인종 집단에 대한 조기 교육 기회를 확대해서 차이를 줄인다<br>
<br>
● AI를 학습시키기 위한 자료를 모으고 분류해서 편향된 정보를 삭제해주는 사이트가 있으면 좋을거 같습니다.<br>
<br>
● AI가 데이터를 학습할때 편향된 데이터인지 판단하는 시스템을 만들어서 편향되지 않은 데이터만 학습하도록 한다<br>
